FALTA PONER BONITO EL MAIN, EL RESTO ESTÁ PERFECTO YA (:

Suposing we do not have missing values nor outliers, we only need to discretize the values of the attributes that are non categorical. We will do this task dividing the values of each numerical column into 4 bins, corresponding to the quartiles (25%, 50%, 75% and 100%). For discretizing we used np.linspace. WE FINALLY DID BINS EQUALLY SIZED, SINCE IN MANY DATAFRAME THE DATA IS INCLINADA HACIA UN VALOR Y POR EJEMPLO SI HAY MUCHOS 0 AL DISCRETIZAR PUEDE SER QUE BINS = [0, 0, 0, 3, 67]. TRY: quartiles, except: bins linspace.

Note that there are some data of the same type and in some cases we may want to discretize and in others don't. For example: in cmc.data "age" and "weducation" are integer attributes, in this case "age" is a numerical attribute that wa may want to discretize but "weducation" is a categorical attribute which takes values from 1=low to 4=high, in this case we want to mantain the actual format of values 1, 2, 3 and 4. For this reason we examined the attributes of each dataset we wanted to classify and introduce 'by-hand' the numerical (integer) attributes that we want to discretize.

Note that, to check the redundancy of a rule we only check that it is redundant with the previous declared rules. We do not mind if it does not classify any unclassified instance since in the test data there may be an instance that could only be classified with that rule. Therefore we may have more rules than instances but these are never redundant rules.

Coverage: The percentage of records which satisfy the antecedent conditions of a particular rule.

The rules generated by the rule-based classifiers are generally not mutually exclusive, i.e. many rules can cover the same record. Note that the coverage of the rules is usually more than 100%, rules are not mutually exclusive. When we look for redundant rules we look for rules "completely contained in" other rules, but for example if we have:
Attribute_1 = yellow --> Class 1
Attribute_2 = big and Attribute_3 = adult --> Class 1
These two rules are not completely contained in each other, nevertheless an instance can verify both rules:
Attribute_1 = yellow, Attribute_2 = big, Attribute_3 = adult, Class = 1


https://sci2s.ugr.es/keel/dataset/data/classification/titanic-names.txt
Description about Titanic Dataset

en la función de test_RULES, en classifier: el return dentro es porque el orden de las reglas importa blablabla...

Si tal decir que en el paper no hay ningún experimento de más de 30 instancias, que es una mierda, y que no probamos con datasets tan pequeños, pero que ni tan mal

LO DEL TAMAÑO DE RULES:
según yo puede haber más reglas que instancias, por qué? pues porque tú cuando miras los posibles valores de los selectors para hacer una nueva regla los miras entre los unclassified instances, PERO para que sea una regla válida se tiene que cumplir para todas las instancias del dataset original. Además, una instancia que fue clasificada por la regla de las básicas como IF Atributo_1 = Valor_1 THEN Class = C1 puede que sea la única instancia que cumpla una regla candidata del tipo IF Atributo_2 = Valor_2 AND Atributo_5 = Valor_5 THEN Class = C3, por tanto esta instancia "daría lugar" mínimo a estas dos reglas, con la idea de poder generalizar lo más posible para el test set.
Estuve releyéndome el paper y me tiene todo el sentido del mundo, porque en los últimos párrafos dice que lo bueno de este algoritmo es que generaliza muy bien y no sé qué, y además si te fijas en la Tabla 9 del paper aparece el número de reglas creadas con RULES y con ID3 para ciertos datasets. El más grande de esos datasets que aparece son Cheese y Flower que tienen ambos 29 instancias. Para Cheese se generan 24 reglas (pocas menos que instancias) mientras que para Flower se generan 56 (casi el doble!). Esto supongo que irá en aumento (la proporción de reglas que se crean "por cada" instancia) a medida que el número de atributos y sus posibles valores aumentan, así que si para un dataset de 5 atributos como es Flower con 27 posibles valores (unos 5 valores distintos por atributo), no es de extrañar que cuando aumenta el número de atributos, tanto como sus posibles valores, el número de reglas que se generan sea mucho mayor que el de instancias.

Decirle que el TITANIC no se clasifica nada bien porque los attributos que tenemos no nos aportan mucha información. En este dataset original los attributos más relevantes para la clasificación son los que no están aquí, por eso obtenemos accuracy bajita.

Note that we started to understand the algorithm with BALLONS datasets. For example, for the adult+stretch data we obtain 4 well classified instances out of 5. The wrong classified one was classified by the third rule, while the fifth rule would classify it correctly. All instances in the test set are classified after examining the third rule, the last three ones are not used but are inferred from the train data in order to be more general just in case many new instances arrive to the classifier. Some examples with 100% accuracy, some with 60%, depending on the split but we have very low number of instances to generalize.

Hablar un poco de la coverage de las reglas, hay reglas que generalizan bien en el train (que igual tienen un coverage de más del 10% o así), pero en general es bajito.
